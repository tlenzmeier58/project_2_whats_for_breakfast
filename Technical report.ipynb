{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e156b6",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc84019",
   "metadata": {},
   "source": [
    "This report details the **E**xtract **T**ransform **L**oad steps taken for this project. 4 datasets were used for this project. 3 were retrieved from [Kaggle.com](https://www.kaggle.com/datasets/pranav941/-world-food-wealth-bank?resource=download&select=crop1.csv). 1 was generator for use in this project from an external website, for which this report details the extraction processes from that external website, and why we extracted it. Also detailed are the transformation steps we took in order to clean our data for user readability and for database loading and accessession. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60123b5",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d39dd6",
   "metadata": {},
   "source": [
    "We began by creating a dataset on continental and country codes from the website [statisticstimes.com](https://statisticstimes.com/geography/countries-by-continents.php). We created this dataset for ideal location grouping and for standardized sorting that the original datasets lacked. We then created a DataFrame from this dataset which we utilize in our transformation. After, we then imported our `crops1` and `live1` .csv file as DataFrames for manipulation. One of our datasets `pop1` is loaded later before its crucial transformation and loading step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408b0bd1",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ad53e8",
   "metadata": {},
   "source": [
    "Starting, we had to reduce dataset filesize for GitHub compliancy. Our original `crops1.csv` is  `105.844MB`, which would be blocked. We reduced the filesize to `89.343MB` which maintained GitHub compliance. We accomplished this by removing any data prior to the date `1980` from crop1.csv, which held data from `1960-2020`. Removal of dates prior to `1980` was kept consistent across the other two datasets, `live1.csv` and `pop1.csv`. The trimmed `crop1` and `live1` are then loaded once again as DataFrames containing 6 columns each:\n",
    "\n",
    "| Area | Item| Element | Year| Unit | Value |\n",
    "|--------|-------|-----------|-------|------|---------|\n",
    "|   Country of Origin  |Specific Crop/Livestock| Relative information of Item | The year| Units relative to Element | Value relative to unit| \n",
    "\n",
    "A seperate DataFrame for either `crops` and `livestock` containing `Item` and `Element` was created, from which a single DataFrame containing both crops and livestock was created. This DataFrame contains a single listing for every item and its corresponding element found in the main two dataframes, which have `1,372,196` entries in crops and `86,018` entries in livestock. \n",
    "\n",
    "In anticipation for database loading we renamed the column names to:\n",
    "\n",
    "\n",
    "|New| country | item_name| item_type | year| item_unit | value |\n",
    "|-|--------|-------|-----------|-------|------|---------|\n",
    "|Old| Area | Item| Element | Year| Unit | Value |\n",
    "\n",
    "Next, from the dataset we created for continental data and country codes, we recieved a DataFrame with 7 columns that we trimmed down to 4: `Country or Area`, `Iso-alpha3 Code`, `Region 1` and `Continent`. In anticipation for database loading we renamed these to: \n",
    "\n",
    "|New| country | country_code | region | continent|\n",
    "|-|--------|-------|-----------|-------|\n",
    "|Old|  Country or Area | Iso-alpha3 Code| Region 1 | Continent| \n",
    "\n",
    "A single listing DataFrame exclusively for years was created in anticipation for database loading. \n",
    "\n",
    "Finally, the `pop1.csv` dataset was loaded as a DataFrame. Null values were dropped and it was merged with countries DataFrame. A unique issue the population DataFrame had was year-wise compliance with our other two DataFrames of crops and livestock. In the population DataFrame, years were by column with country listed by row. The pandas method `.melt` was utilized to remedy this problem - which required initial setup to function properly. A list of the years was created from the single listing DataFrame for years. The list had all its integer values converted to strings. The pandas method was then able to properly function and create a DataFrame that shared dimensions with crops and livestock, and therefore share table compliance when loaded and queried from the database later. \n",
    "\n",
    "As with the rest, in anticipation of database loading we renamed the column names from population:\n",
    "\n",
    "|New| country | country_code |\n",
    "|-|--------|-------|\n",
    "|Old|  Country | Country Code|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9dd934",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c488897",
   "metadata": {},
   "source": [
    "Finally, our data was loaded into a PostgreSQL database using `sqlalchemy`. Our schema was created to contain 6 tables:\n",
    "\n",
    "- `tbl_item` \n",
    "- `tbl_crops` \n",
    "- `tbl_livestock` \n",
    "- `tbl_countries` \n",
    "- `tbl_population` \n",
    "- `tbl_year`\n",
    "\n",
    "which the data was loaded into vis a vis each `tbl_` for pertinent information from our transformed DataFrames. This process is not autonomous. To update the user will have to periodically, likely on a year-to-year basis load the database with the previous years new data. The process should be effortless, given instruction is properly followed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
